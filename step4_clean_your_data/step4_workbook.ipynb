{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Clean Your Data\n",
    "Now, we will experiment and explore differnt functions that import data, examine the details of the data (and how messy they are!), manipulate the data, and export the data. This process is one of the most fundamental and important things that researchers do with Python.\n",
    "\n",
    "The purpose of this notebook is to get familiar with how these functions work. Once you have a handle of the key functions, we'll create a clean and well-documented script to clear our data.\n",
    "\n",
    "I've laid out 7 steps that you'll need to clean data; this is a basic structure so that you learn the various functions that you'll need later on. The goal here is to mess around with all of these functions and learn through trial-and-error.\n",
    "\n",
    "To clean the data we need to:\n",
    "1. **Import packages** into your notebook.\n",
    "2. **Import your raw data** into your notebook.\n",
    "3. Understand **what the data are** and **how the data are stored**.\n",
    "4. **Change data** that are not stored in the way that best fits your needs.\n",
    "5. **Delete data** that you do not want.\n",
    "6. **Create data** that we need.\n",
    "7. **Export the cleaned data** to a file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path as fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will import pandas, numpy, and os into your notebook that vast majority of the time.  \n",
    "Notice that instead of importing the entire `os` package, I only imported the `path` module. Remeber that packages are collections of modules and modules are collections of functions. I also labeled this module `fp`, which is short for filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the raw data, we need to tell JupyterLab where to find it.  \n",
    "To direct JupyterLab to the data file, we need to define a file path.  \n",
    "To define a file path, we first define our current directory. The current directory is where this notebook is located in our Finder.\n",
    "\n",
    "`fp.abspath()` with `''` as an input will tell me what file directory I am currently working in.\n",
    "\n",
    "- Type the following in to the cell below and execute the code:\n",
    "\n",
    "```python\n",
    "current_directory = fp.abspath('')\n",
    "current_directory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the the file directory that we are currently working in to the variable `current_directory` and previews that variable in JupyterLab. If we look in our finder, we can see that this filepath refers to where our Jupyter Notebook file is saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to figure out where the data are **relative** to our current directory. These are called **relative paths**; defining filepaths relative to where your notebook is really important for other people to be able to run your code. The code that we will use to define the relative filepath is essentially a set of directions to navigate from this Jupyter Notebook file to the raw data file.  \n",
    "\n",
    "We are going to use two functions from the path module to do this:\n",
    "1. `fp.dirname()`: `dirname()` is short for directory name and will return the folder that contains the filepath that you enter.\n",
    "2. `fp.join()`: `join()` will add folder names to the file path.\n",
    "\n",
    "\n",
    "`fp.dirname(current_directory)` will return the folder that this notebook file is in. We can nest this function multiple times (e.g. `fp.dirname(fp.dirname(current_directory))` to return higher and higher level folders.  \n",
    "\n",
    "For example,\n",
    "```python\n",
    "fp.dirname(fp.dirname('/Users/alex/folder1/folder2'))\n",
    "```\n",
    "will return the filepath\n",
    "```python\n",
    "'/Users/alex'\n",
    "```\n",
    "\n",
    "\n",
    "`fp.join()` will add folders and files to the filepath.\n",
    "\n",
    "For example,\n",
    "```python\n",
    "fp.join('/Users/alex', 'data_folder', 'data_file.csv)\n",
    "``` \n",
    "would return the filepath\n",
    "```python\n",
    "'/Users/alex/data_folder/data_file.csv'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the cell below, use the `fp.dirname()` and `fp.join()` functions to define a path from your current directory to the data file. Try writing out the code and previewing the data until you get it right.\n",
    "- Save the file path in a variable named `data_filepath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined where the data are, we are going to use pandas to load the data into our notebook.\n",
    "If you have an excel file, you are going to use the `read_excel()` function; if you have a csv file, you are going to use the `read_csv()` function in `pandas`.  \n",
    "These read functions take the `data_filepath` as the input.\n",
    "\n",
    "- Import your data into Jupyter Lab by typing in and executing the following code in the cell below. Swap out `read_csv` with `read_excel` if needed. The `head()` function shows a preview of the top 5 rows of the table.\n",
    "\n",
    "```python\n",
    "raw_data = pd.read_csv(data_filepath)\n",
    "raw_data.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have your data in JupyterLab! It is stored as a pandas **[DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)** .  \n",
    "DataFrames have an **[Index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.html)**; the indices are the row numbers and the column names.  \n",
    "DataFrames are made up or rows as columns; each row or each column by itself is a **[Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)** .  \n",
    "\n",
    "- Save a copy of the data as `df` (short for DataFrame) by executing the code in the cell below.\n",
    "\n",
    "This way, we'll always be able to refer back to the raw data without loading it back in from the file. From here on, we'll only mess around with our data as `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What Are the Data & How Are They Stored\n",
    "**The goal of this section** is to use a bunch of different functions to select parts of your data from your DataFrame.  \n",
    "To change, delete, or manipulate data you'll need to be able to select portions of it.\n",
    "\n",
    "To select portions of the data we are going to use the `.loc[]` and `.iloc[]` functions. For more information on what input these functions take, what they output, and what errors they may raise, check the documentation:\n",
    "- [.loc[] documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html)\n",
    "- [.iloc[] documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)\n",
    "\n",
    "Here is a list of data types that may or may not be in your data table:\n",
    "1. DataFrame\n",
    "2. Series\n",
    "3. String\n",
    "4. Integer\n",
    "5. Float\n",
    "\n",
    "To practice selecting portions of your data, use the `.loc[]` and `.iloc[]` functions to select a portion of the data. \n",
    "\n",
    "Here are three examples of using this code:\n",
    "```python\n",
    "df.loc[10, 'user_id'] OR df.loc[:, 'user_id'] OR df.loc[10, :]\n",
    "```\n",
    "where there first example returns data from row 10 of the user_id column; the second returns all rows of the user_id colum; the third returns all columns of row 10.  \n",
    "To identify the type of data that you just selected, use the `type()` function:\n",
    "```python\n",
    "type(df.loc[10,'user_id'])\n",
    "```\n",
    "\n",
    "- In the cell below, use the `.loc[]` and `.iloc[]` function to select portions of your dataframe that match each data type above. Confirm the type of your data selection using the `type()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to select data in your dataframe; I've listed a few important ones here. Note that `name_of_your_column`, `your_column_prefix`, `your_value` are placeholders; you should replace that with your column headers or your data.\n",
    "1. Select a column [returns a Series]:\n",
    "\n",
    "```python\n",
    "df.name_of_your_column OR df['name_of_your_column']\n",
    "```\n",
    "\n",
    "2. Select multiple columns [returns a DataFrame] using a list of column names. You can create this list by writing out the column names explicitly or using list comprehension:\n",
    "\n",
    "```python\n",
    "df[['name_of_your_column1', 'name_of_your_column2']] OR\n",
    "df[[i for i in df.columns if 'your_column_prefix' in i]]\n",
    "```\n",
    "\n",
    "3. Select multiple rows using [returns a DataFrame] a conditional statement where conditional statements can be things like:\n",
    "\n",
    "```python\n",
    "df[df.name_of_your_column == your_value] OR\n",
    "df[df.name_of_your_column != your_value] OR\n",
    "df[df.name_of_your_column.isin([your_list])] OR\n",
    "df[df.name_of_your_column.notnull()] OR\n",
    "df[df.name_of_your_column.isnull()]\n",
    "```\n",
    "\n",
    "- In the cell below, use each of these three techniques to select portions of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may have noticed:\n",
    "1. Many of these functions use brackets `[]` rather than parentheses `()`; functions that slice/select data use brackets &rarr; check out this [link](https://lerner.co.il/2018/06/08/python-parentheses-primer/) for more detailed info on when to use `[]`vs.`()`vs.`{}`\n",
    "\n",
    "2. These functions are called right on the data `df.rename()`, rather than being called from a module like `fp.abspath()`. DataFrames have **attributes**; attributes are functions that work directly on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Change Data\n",
    "**The goal of this section** is to use the functions/techniques below to change the data in your DataFrame.  \n",
    "\n",
    "To change portions of the data we are going to use the `rename()`, `replace()`, and `map()` functions. For more information on what input these functions take, what they output, and what errors they may raise, check the documentation:\n",
    "1. [rename() documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html)\n",
    "2. [replace() documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) \n",
    "3. [map() documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html)\n",
    "\n",
    "You can also change portions of the data by:\n",
    "1. Selecting a set of values using the `loc[]` or `iloc[]` function and set it equal to a new value\n",
    "\n",
    "```python\n",
    "df.loc[10, 'user_id'] = 9999\n",
    "```\n",
    "\n",
    "\n",
    "- In the cell below, try selecting portions of data and changing them using each of the functions/techniques above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Delete Data\n",
    "**The goal of this section** is to use the functions/techniques below to delete data in your DataFrame.  \n",
    "To delete portions of the data we are going to use the `drop()` function. For more information on what input these functions take, what they output, and what errors they may raise, check the documentation:\n",
    "1. [drop() documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\n",
    "\n",
    "You can also delete portions of the data by:\n",
    "1. Saving the dataframe as set of values using the `loc[]` or `iloc[]` function\n",
    "\n",
    "```python\n",
    "df = df.loc[30:300, ['user_id', 'your_column1', 'your_column2']]\n",
    "```\n",
    "\n",
    "2. Saving the dataframe as only certain columns\n",
    "\n",
    "```python\n",
    "df = df[['user_id', 'your_column1', 'your_column2']]\n",
    "```\n",
    "\n",
    "3. Saving the dataframe as only certain rows using a conditional statement\n",
    "```python\n",
    "df = df[df.name_of_your_column > your_value]\n",
    "```\n",
    "- In the cell below, try selecting portions of data and deleting them using each of the functions/techniques above. \n",
    "\n",
    "Note the first line of code I put in (and don't delete it). While you are practicing deleting data, you need to start with a fresh copy of the dataframe each time. If you delete user_id from the dataframe, and then run the code again, it will throw an error because user_id is no longer in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Data\n",
    "**The goal of this section** is to use the functions/techniques below to create/add data to your DataFrame.  \n",
    "Most often, when we need to create data and add it to our dataframe, we are going to create new columns. To add a new column to our dataframe, we define a new column name and set it equal to data:\n",
    "\n",
    "```python\n",
    "df['your_new_column_name'] = some_data_that_you_create\n",
    "```\n",
    "\n",
    "The harder part is creating the data that we want to add. It is important to remember that the column that you want to add has to have the same number of rows as your dataframe. To create data to add to our dataframe, we are going to use the `where()` function. For more information on what input these functions take, what they output, and what errors they may raise, check the documentation:\n",
    "1. [np.where()](https://numpy.org/doc/stable/reference/generated/numpy.where.html)\n",
    "\n",
    "You can also create data to add to your dataframe by creating lists of data; for example:\n",
    "1. Create a list of numbers from 0 to n, where n is the length of your dataframe:\n",
    "\n",
    "```python\n",
    "df['your_new_column_name'] = [i for i in range(len(df))]\n",
    "```\n",
    "\n",
    "2. Create a list of values based on another column in your dataframe\n",
    "\n",
    "```python\n",
    "df['your_new_column_name'] = [i if i > 1 else i*10 for i in df.name_of_your_column]\n",
    "```\n",
    "\n",
    "3. Create a list of combines values from two different columns based on a conditional statement\n",
    "\n",
    "```python\n",
    "df['your_new_column_name'] = [df.loc[idx, 'column1'] if df.loc[idx,'column0'] == TRUE else df.loc[idx,'column2'] for idx in df.index]\n",
    "```\n",
    "\n",
    "- In the cell below, try creating data and adding it to your dataframe using each of the functions/techniques above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export the Cleaned Data\n",
    "Last, we'll export the \"cleaned data\" (here it might just be changed in a bunch of ways) to files in the finder. \n",
    "We can export our dataframes to multiple formats; I would recommend Excel files and HDF files.  \n",
    "\n",
    "Excel files are widely used and accesible for most people; however, it is not an open source format and, for large files, can take a long time to read files or create files.   \n",
    "\n",
    "HDF files are saved as a pandas dataframes; there is no data conversion happening so files can be read and created very quickly. The only downside is that people are less familiar with this data format.\n",
    "\n",
    "- Add the date yyyymmdd format and the name of your data; when you execute the code, the cleaned data will be save right next to this notebook.\n",
    "- If you would like to change where the data are saved (e.g. a cleaned_data folder), use the `dirname()` and `join()` functions to define a filepath to a different folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- date in the form year, month, day (yyyymmdd)\n",
    "date =\n",
    "# ---- name describing the data using _ for spaces or camelcase; for example:\n",
    "# ---- happiness_and_productivity_survey OR HappinessAndProductivitySurvey\n",
    "name_of_data = \n",
    "\n",
    "# ---- export to excel\n",
    "df.to_excel(fp.join(current_directory, '{}_cleaned_{}.xlsx'.format(date, name_of_data)))\n",
    "\n",
    "# ---- export to open source format\n",
    "df.to_hdf(fp.join(current_directory, '{}_cleaned_{}.h5'.format(date, name_of_data)), 'data')\n",
    "\n",
    "del date, name_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Nice job!\n",
    "You can now write Python scripts to clean your own data! You will never have to clean data by hand again. If you run a similar experiment or survey in the future, you'll just have to tweak/update this code; 90% of the work will already be done. If a teammate or colleague runs a similar experiment or survey, you'll just have to tweak/update this code; you'll have done 90% of the work for them and you'll be a lifesaver!\n",
    "\n",
    "You now have data superpowers - congratulations!\n",
    "\n",
    "Unfortunately, you've beat me to `step5_describe_your_data`. I still need to create the workbook for this. Please send me an email @ alexdsbreslav@gmail.com and tell me to hurry up!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thriving_spring2020]",
   "language": "python",
   "name": "conda-env-thriving_spring2020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
